{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mock CSV with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B     C    D\n",
      "0   1.0   2.0   3.0  4.0\n",
      "1   5.0   6.0   NaN  8.0\n",
      "2  10.0  11.0  12.0  NaN\n"
     ]
    }
   ],
   "source": [
    "csv_data = \\\n",
    "'''A,B,C,D\n",
    "1.0,2.0,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "10.0,11.0,12.0,'''\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0\n",
       "B    0\n",
       "C    1\n",
       "D    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validates how many rows have missing values per column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing data by removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0  1.0  2.0  3.0  4.0\n",
      "\n",
      "      A     B\n",
      "0   1.0   2.0\n",
      "1   5.0   6.0\n",
      "2  10.0  11.0\n",
      "\n",
      "      A     B     C    D\n",
      "0   1.0   2.0   3.0  4.0\n",
      "1   5.0   6.0   NaN  8.0\n",
      "2  10.0  11.0  12.0  NaN\n",
      "\n",
      "     A    B    C    D\n",
      "0  1.0  2.0  3.0  4.0\n",
      "\n",
      "      A     B     C    D\n",
      "0   1.0   2.0   3.0  4.0\n",
      "2  10.0  11.0  12.0  NaN\n"
     ]
    }
   ],
   "source": [
    "print(df.dropna(axis=0)) # Drops rows with missing values\n",
    "print()\n",
    "\n",
    "print(df.dropna(axis=1)) # Drops columns with missing values\n",
    "print()\n",
    "\n",
    "print(df.dropna(how='all')) # Drops rows where all columns are NaN\n",
    "print()\n",
    "\n",
    "print(df.dropna(thresh=4)) # Drops rows that have less than 4 real values\n",
    "print()\n",
    "\n",
    "print(df.dropna(subset=['C'])) # Drops rows where NaN appears in specific columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping missing values is definitely the easiest way to handle data cleanup, but it does come with its downsides. As we remove columns, there is potential to remove features that contain valuable information. Also if we remove enough rows we can severly degrade our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   2.   3.   4. ]\n",
      " [ 5.   6.   7.5  8. ]\n",
      " [10.  11.  12.   6. ]]\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values with the mean of the column\n",
    "imr = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imr = imr.fit(df.values) # Although dataframes are supported by sklearn, the API has matured more to work with numpy arrays\n",
    "\n",
    "imputed_data = imr.transform(df.values)\n",
    "print(imputed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other forms of imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  3.  8.]\n",
      " [10. 11. 12.  4.]]\n",
      "\n",
      "[[ 1.   2.   3.   4. ]\n",
      " [ 5.   6.   7.5  8. ]\n",
      " [10.  11.  12.   6. ]]\n"
     ]
    }
   ],
   "source": [
    "imr = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imr = imr.fit(df.values)\n",
    "imputed_data = imr.transform(df.values)\n",
    "print(imputed_data)\n",
    "print()\n",
    "\n",
    "imr = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imr = imr.fit(df.values)\n",
    "imputed_data = imr.transform(df.values)\n",
    "print(imputed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   7.5  8.0\n",
       "2  10.0  11.0  12.0  6.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(df.mean()) # Fills missing values with the mean of the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn estimator API used in the SimpleImputer class is a type of transformer that is fitted to the training data. It can then be used to transform the training data and any future data (of the same size) that we want to predict on.\n",
    "\n",
    "Why use the same transformer on different datasets?\n",
    "\n",
    "- The reason we want to use the same transformer on different datasets is for consistency across data that will be used for training a model.\n",
    "- Fitting a transformer once can be more efficient for larger datasets.\n",
    "- Transfer of knowledge, the information learned from one dataset can be applied to another dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
